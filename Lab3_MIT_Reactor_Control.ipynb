{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3 MIT Reactor Control.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPt8SnpqjpBbB9heLMice98",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yan-Erin/ML-AI-MiniProjects/blob/main/Lab3_MIT_Reactor_Control.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsMqmckzlbE8",
        "outputId": "c87df472-1469-4bec-d8cf-888f09ff6723"
      },
      "source": [
        "#Setup Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('/content/gdrive/MyDrive')\n",
        "#Basic packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2  #for plotting the MIT reactor core\n",
        "#Sklearn tools\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#Keras specials\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "#External path\n",
        "mitr_path='/content/gdrive/MyDrive/course_data/mitr_temp.png'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hSxWPftbl-Fp",
        "outputId": "884265ee-4f89-46e5-b264-dd4eac911a8f"
      },
      "source": [
        "#Exercise 1\n",
        "'''\n",
        "a) There is 196 inputs/features and 3 outputs\n",
        "b) The network depth is 5 because it has 5 hidden layers\n",
        "c) each neuron in each layer connects to all neurons in next layer\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\na) There is 196 inputs/features and 3 outputs\\nb) The network depth is 5 because it has 5 hidden layers\\nc) each neuron in each layer connects to all neurons in next layer\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AlGn2WffoAGr",
        "outputId": "02b3d670-f4e0-4b17-82d4-c3c054eebf2e"
      },
      "source": [
        "#Exercise 2\n",
        "xurl='https://raw.githubusercontent.com/MajdiRadaideh/S097data/main/crx.csv'\n",
        "yurl='https://raw.githubusercontent.com/MajdiRadaideh/S097data/main/powery.csv'\n",
        "xdata=pd.read_csv(xurl)\n",
        "ydata =pd.read_csv(yurl)\n",
        "print(xdata.shape, ydata.shape)\n",
        "xdata= xdata.to_numpy()\n",
        "ydata=ydata.to_numpy()\n",
        "\n",
        "#set training data\n",
        "xtrain= xdata[:901]\n",
        "ytrain=ydata[0:901]\n",
        "\n",
        "#Set testing data\n",
        "xtest= xdata[901:]\n",
        "ytest= ydata[901:]\n",
        "\n",
        "#Input output scaling\n",
        "xscaler = MinMaxScaler()\n",
        "yscaler = MinMaxScaler()\n",
        "Xtrain = xscaler.fit_transform(xtrain)\n",
        "Xtest = xscaler.transform(xtest)\n",
        "Ytrain = yscaler.fit_transform(ytrain)\n",
        "Ytest = yscaler.transform(ytest)\n",
        "\n",
        "#Making the NN\n",
        "model = Sequential()\n",
        "#layer1\n",
        "model.add(Dense(100, activation = \"relu\", kernel_initializer = 'normal'))\n",
        "model.add(Dropout(0.5))\n",
        "#layer2\n",
        "model.add(Dense(200, activation = \"relu\", kernel_initializer = 'normal'))\n",
        "\n",
        "#layer3\n",
        "model.add(Dense(200, activation = \"relu\", kernel_initializer = 'normal'))\n",
        "\n",
        "#layer4\n",
        "model.add(Dense(200, activation = \"relu\", kernel_initializer = 'normal'))\n",
        "\n",
        "#layer5\n",
        "model.add(Dense(200, activation = \"relu\", kernel_initializer = 'normal'))\n",
        "\n",
        "\n",
        "#layer8\n",
        "model.add(Dense(ytrain.shape[1], activation = \"linear\", kernel_initializer = 'normal'))\n",
        "\n",
        "model.compile(loss='mean_absolute_error', optimizer=Adam(learning_rate=4.2e-4), metrics=['mean_absolute_error'])\n",
        "\n",
        "\n",
        "redlr= ReduceLROnPlateau(monitor='val_mean_absolute_error', factor=0.9, patience=5, verbose=1, min_lr = 0)\n",
        "history=model.fit(Xtrain, Ytrain, epochs=100, batch_size=16, validation_split = 0.15, callbacks=redlr, verbose=True)\n",
        "model.summary()\n",
        "\n",
        "train_err=history.history['mean_absolute_error']\n",
        "val_err=history.history['val_mean_absolute_error']\n",
        "\n",
        "# plot the training/validation MAE on the same plot\n",
        "plt.figure()\n",
        "plt.plot(train_err, label='Training')\n",
        "plt.plot(val_err, label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "Ynn = model.predict(Xtest)\n",
        "Ynn=yscaler.inverse_transform(Ynn)\n",
        "Ytest=yscaler.inverse_transform(Ytest)\n",
        "print(\"MAE: \", mean_absolute_error(Ynn,Ytest), \"r^2: \", r2_score(Ynn,Ytest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 6) (1000, 22)\n",
            "Epoch 1/100\n",
            "48/48 [==============================] - 2s 12ms/step - loss: 0.3977 - mean_absolute_error: 0.3977 - val_loss: 0.1774 - val_mean_absolute_error: 0.1774\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1826 - mean_absolute_error: 0.1826 - val_loss: 0.1717 - val_mean_absolute_error: 0.1717\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1749 - mean_absolute_error: 0.1749 - val_loss: 0.1689 - val_mean_absolute_error: 0.1689\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1699 - mean_absolute_error: 0.1699 - val_loss: 0.1595 - val_mean_absolute_error: 0.1595\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1117 - val_mean_absolute_error: 0.1117\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1175 - mean_absolute_error: 0.1175 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1002 - mean_absolute_error: 0.1002 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0880 - mean_absolute_error: 0.0880 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0762 - mean_absolute_error: 0.0762 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0351 - val_mean_absolute_error: 0.0351\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0635 - mean_absolute_error: 0.0635 - val_loss: 0.0315 - val_mean_absolute_error: 0.0315\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0602 - mean_absolute_error: 0.0602 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0607 - mean_absolute_error: 0.0607 - val_loss: 0.0406 - val_mean_absolute_error: 0.0406\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0586 - mean_absolute_error: 0.0586 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0573 - mean_absolute_error: 0.0573 - val_loss: 0.0354 - val_mean_absolute_error: 0.0354\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0580 - mean_absolute_error: 0.0580 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0540 - mean_absolute_error: 0.0540 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0351 - val_mean_absolute_error: 0.0351\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0546 - mean_absolute_error: 0.0546 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0551 - mean_absolute_error: 0.0551 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0522 - mean_absolute_error: 0.0522 - val_loss: 0.0239 - val_mean_absolute_error: 0.0239\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0525 - mean_absolute_error: 0.0525 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0529 - mean_absolute_error: 0.0529 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0506 - mean_absolute_error: 0.0506 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00037799999699927866.\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0520 - mean_absolute_error: 0.0520 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0504 - mean_absolute_error: 0.0504 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0515 - mean_absolute_error: 0.0515 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0487 - mean_absolute_error: 0.0487 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0475 - mean_absolute_error: 0.0475 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0501 - mean_absolute_error: 0.0501 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0486 - mean_absolute_error: 0.0486 - val_loss: 0.0253 - val_mean_absolute_error: 0.0253\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003401999972993508.\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0499 - mean_absolute_error: 0.0499 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0474 - mean_absolute_error: 0.0474 - val_loss: 0.0248 - val_mean_absolute_error: 0.0248\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0482 - mean_absolute_error: 0.0482 - val_loss: 0.0239 - val_mean_absolute_error: 0.0239\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0473 - mean_absolute_error: 0.0473 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0486 - mean_absolute_error: 0.0486 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0478 - mean_absolute_error: 0.0478 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0467 - mean_absolute_error: 0.0467 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0483 - mean_absolute_error: 0.0483 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0488 - mean_absolute_error: 0.0488 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0480 - mean_absolute_error: 0.0480 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003061800001887605.\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0462 - mean_absolute_error: 0.0462 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0463 - mean_absolute_error: 0.0463 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0477 - mean_absolute_error: 0.0477 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0475 - mean_absolute_error: 0.0475 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0474 - mean_absolute_error: 0.0474 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00027556200802791864.\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0474 - mean_absolute_error: 0.0474 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0471 - mean_absolute_error: 0.0471 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0469 - mean_absolute_error: 0.0469 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0468 - mean_absolute_error: 0.0468 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0457 - mean_absolute_error: 0.0457 - val_loss: 0.0240 - val_mean_absolute_error: 0.0240\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0002480057941284031.\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0258 - val_mean_absolute_error: 0.0258\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0455 - mean_absolute_error: 0.0455 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0458 - mean_absolute_error: 0.0458 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0471 - mean_absolute_error: 0.0471 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002232052094768733.\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0450 - mean_absolute_error: 0.0450 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0463 - mean_absolute_error: 0.0463 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0456 - mean_absolute_error: 0.0456 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0445 - mean_absolute_error: 0.0445 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0438 - mean_absolute_error: 0.0438 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0445 - mean_absolute_error: 0.0445 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0002008846859098412.\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0445 - mean_absolute_error: 0.0445 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0446 - mean_absolute_error: 0.0446 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0463 - mean_absolute_error: 0.0463 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0451 - mean_absolute_error: 0.0451 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0453 - mean_absolute_error: 0.0453 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.00018079621077049524.\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0434 - mean_absolute_error: 0.0434 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0451 - mean_absolute_error: 0.0451 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0432 - mean_absolute_error: 0.0432 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0439 - mean_absolute_error: 0.0439 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0447 - mean_absolute_error: 0.0447 - val_loss: 0.0240 - val_mean_absolute_error: 0.0240\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00016271658969344572.\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0450 - mean_absolute_error: 0.0450 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0437 - mean_absolute_error: 0.0437 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0433 - mean_absolute_error: 0.0433 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0436 - mean_absolute_error: 0.0436 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0444 - mean_absolute_error: 0.0444 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0001464449320337735.\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0427 - mean_absolute_error: 0.0427 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0436 - mean_absolute_error: 0.0436 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0437 - mean_absolute_error: 0.0437 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0433 - mean_absolute_error: 0.0433 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.00013180043752072378.\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0421 - mean_absolute_error: 0.0421 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0419 - mean_absolute_error: 0.0419 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0424 - mean_absolute_error: 0.0424 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00011862039245897904.\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0424 - mean_absolute_error: 0.0424 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0433 - mean_absolute_error: 0.0433 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.0430 - mean_absolute_error: 0.0430 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0430 - mean_absolute_error: 0.0430 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0421 - mean_absolute_error: 0.0421 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0427 - mean_absolute_error: 0.0427 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.00010675835583242589.\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0425 - mean_absolute_error: 0.0425 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0434 - mean_absolute_error: 0.0434 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.0424 - mean_absolute_error: 0.0424 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_87 (Dense)             (None, 100)               700       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 22)                4422      \n",
            "=================================================================\n",
            "Total params: 145,922\n",
            "Trainable params: 145,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "MAE:  28.35435901988641 r^2:  0.9803016300179437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}